{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first beginning of our job is to import packages and setting environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-72-243.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use `SparkContext` to parse the XML file that we need to analyze, which is \"Posts.xml\" in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"utf-8\"?>',\n",
       " '<posts>',\n",
       " '  <row Id=\"1\" PostTypeId=\"1\" AcceptedAnswerId=\"9\" CreationDate=\"2010-07-20T19:09:27.200\" Score=\"156\" ViewCount=\"8964\" Body=\"&lt;p&gt;Can someone explain to me how there can be different kinds of infinities?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was reading &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/The_Man_Who_Loved_Only_Numbers&quot; rel=&quot;noreferrer&quot;&gt;The man who loved only numbers&lt;/a&gt;&quot; by &lt;a href=&quot;http://en.wikipedia.org/wiki/Paul_Hoffman_(science_writer)&quot; rel=&quot;noreferrer&quot;&gt;Paul Hoffman&lt;/a&gt; and came across the concept of countable and uncountable infinities, but they\\'re only words to me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be appreciated.&lt;/p&gt;&#xA;\" OwnerUserId=\"10\" LastEditorUserId=\"32803\" LastEditorDisplayName=\"user126\" LastEditDate=\"2018-03-01T19:53:22.017\" LastActivityDate=\"2020-01-28T03:26:12.530\" Title=\"What Does it Really Mean to Have Different Kinds of Infinities?\" Tags=\"&lt;elementary-set-theory&gt;&lt;intuition&gt;&lt;infinity&gt;&lt;faq&gt;\" AnswerCount=\"9\" CommentCount=\"0\" FavoriteCount=\"44\" ContentLicense=\"CC BY-SA 3.0\" />',\n",
       " '  <row Id=\"3\" PostTypeId=\"1\" CreationDate=\"2010-07-20T19:12:14.353\" Score=\"120\" ViewCount=\"71991\" Body=\"&lt;p&gt;&lt;a href=&quot;http://mathfactor.uark.edu/&quot;&gt;mathfactor&lt;/a&gt; is one I listen to.  Does anyone else have a recommendation?&lt;/p&gt;&#xA;\" OwnerUserId=\"29\" LastEditorUserId=\"498\" LastEditorDisplayName=\"user126\" LastEditDate=\"2012-07-31T13:58:15.730\" LastActivityDate=\"2020-04-23T02:46:35.977\" Title=\"List of interesting math podcasts?\" Tags=\"&lt;soft-question&gt;&lt;big-list&gt;&lt;online-resources&gt;\" AnswerCount=\"21\" CommentCount=\"4\" FavoriteCount=\"80\" CommunityOwnedDate=\"2010-07-20T20:35:23.263\" ContentLicense=\"CC BY-SA 3.0\" />',\n",
       " '  <row Id=\"4\" PostTypeId=\"2\" ParentId=\"3\" CreationDate=\"2010-07-20T19:14:10.603\" Score=\"11\" Body=\"&lt;p&gt;&lt;a href=&quot;http://www.bbc.co.uk/podcasts/series/moreorless&quot; rel=&quot;noreferrer&quot;&gt;More or Less&lt;/a&gt; is a BBC Radio 4 programme about maths and statistics in the news, and there is a free podcast. It\\'s presented by &lt;a href=&quot;http://timharford.com/&quot; rel=&quot;noreferrer&quot;&gt;Tim Harford&lt;/a&gt;, the Undercover Economist from the &lt;a href=&quot;http://www.ft.com/home/uk&quot; rel=&quot;noreferrer&quot;&gt;Financial Times&lt;/a&gt;.&lt;/p&gt;&#xA;\" OwnerUserId=\"31\" LastActivityDate=\"2010-07-20T19:14:10.603\" CommentCount=\"2\" CommunityOwnedDate=\"2010-07-20T20:35:23.263\" ContentLicense=\"CC BY-SA 2.5\" />']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = sc.textFile(\"s3://my4dbucket/math/Posts.xml\")\n",
    "textFile.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we take the first 5 elements of this file, we can see that xml file is formatted much like an HTML document, but uses custom tags to define objects and the data within each object. The `Posts` consists of 20 'object': \n",
    "* Id\n",
    "* PostTypeId\n",
    "* ParentID\n",
    "* AcceptedAnswerId\n",
    "* CreationDate\n",
    "* Score\n",
    "* ViewCount\n",
    "* Body\n",
    "* OwnerUserId\n",
    "* LastEditorUserId\n",
    "* LastEditorDisplayName=\"Jeff Atwood\"\n",
    "* LastEditDate\n",
    "* LastActivityDate\n",
    "* CommunityOwnedDate\n",
    "* ClosedDate\n",
    "* Title\n",
    "* Tags\n",
    "* AnswerCount\n",
    "* CommentCount\n",
    "* FavoriteCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 2983556 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2983556"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import packages needed for execute sql and binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our binary model intends to tag questions related and unrelated to 'calculus': there are 4 objects may be related to our prediction:`Id` `Title` `Body` `Tags`(this object is for validation and testing), so for the first step, we exclude rows with missing values of 4 objects mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsXml = textFile.map( lambda line: line.strip() ).\\\n",
    "    filter( lambda line: line != \"<posts>\" and line != \"</posts>\").\\\n",
    "    filter( lambda line: not line.startswith(\"<?xml version=\") ).\\\n",
    "    filter( lambda line: line.find(\"Id=\") >= 0 ).\\\n",
    "    filter( lambda line: line.find(\"Tags=\") >= 0 ).\\\n",
    "    filter( lambda line: line.find(\"Body=\") >= 0 ).\\\n",
    "    filter( lambda line: line.find(\"Title=\") >= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2983556\n",
      "1257199\n"
     ]
    }
   ],
   "source": [
    "print(textFile.count())\n",
    "print(postsXml.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we filtered almost half of the rows, reducing the size of this RDD will help us a lot in terms of computational costs.\n",
    "\n",
    "Intuitively, the tag we give to a certain question is base on both the question itself(`Title`) and further description of the question(`Body`), so we merge these 2 objects into one object `Text`, and we use ****lambda**** function to extract the objects and contents we need. We define Label = 1.0 for Tags = 'calculus', otherwise Label = 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "targetTag = \"calculus\"\n",
    "postsRDD = postsXml.map( lambda s: Row(\\\n",
    "                Id = re.search('Id=\".+?\"', s).group(0)[4:-1],\\\n",
    "                Label = 1.0 if re.search('Tags=\".+?\"', s) != None\\\n",
    "                            and re.search('Tags=\".+?\"', s).group(0)[6:-1].find(targetTag) >= 0 else 0.0,\\\n",
    "                Text = ((re.search('Title=\".+?\"', s).group(0)[7:-1] if re.search('Title=\".+?\"', s) != None else \"\") + \" \" + (re.search('Body=\".+?\"', s).group(0)[6:-1]) if re.search('Body=\".+?\"', s) != None else \"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PostsLabeled = sqlContext.createDataFrame(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way for create data frame: we create a schema first.\n",
    "#dfSchema = StructType([\n",
    "        #StructField(\"Id\", StringType(), True),\\\n",
    "        #StructField(\"Label\", FloatType(), True),\\\n",
    "        #StructField(\"Text\", StringType(), True)\n",
    "        #])\n",
    "#PostsLabeled = sqlContext.createDataFrame(postsRDD, dfSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that \"PostsLabeled\" only includes ID, Label, and Text that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='1', Label=0.0, Text=\"What Does it Really Mean to Have Different Kinds of Infinities? &lt;p&gt;Can someone explain to me how there can be different kinds of infinities?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was reading &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/The_Man_Who_Loved_Only_Numbers&quot; rel=&quot;noreferrer&quot;&gt;The man who loved only numbers&lt;/a&gt;&quot; by &lt;a href=&quot;http://en.wikipedia.org/wiki/Paul_Hoffman_(science_writer)&quot; rel=&quot;noreferrer&quot;&gt;Paul Hoffman&lt;/a&gt; and came across the concept of countable and uncountable infinities, but they're only words to me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be appreciated.&lt;/p&gt;&#xA;\"),\n",
       " Row(Id='3', Label=0.0, Text='List of interesting math podcasts? &lt;p&gt;&lt;a href=&quot;http://mathfactor.uark.edu/&quot;&gt;mathfactor&lt;/a&gt; is one I listen to.  Does anyone else have a recommendation?&lt;/p&gt;&#xA;'),\n",
       " Row(Id='5', Label=0.0, Text='How can you prove that the square root of two is irrational? &lt;p&gt;I have read a few proofs that $\\\\sqrt{2}$ is irrational.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have never, however, been able to really grasp what they were talking about.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a simplified proof that $\\\\sqrt{2}$ is irrational?&lt;/p&gt;&#xA;'),\n",
       " Row(Id='6', Label=0.0, Text=\"What is your favorite online graphing tool? &lt;p&gt;I'm looking for a nice, quick online graphing tool. The ability to link to, or embed the output would be handy, too.&lt;/p&gt;&#xA;\"),\n",
       " Row(Id='8', Label=0.0, Text=\"How are we able to calculate specific numbers in the Fibonacci Sequence? &lt;p&gt;I was reading up on the Fibonacci Sequence,  $\\\\text {{1,1,2,3,5,8,13,....}}$ when I've noticed some were able to calculate specific numbers. So far I've only figured out creating an array and counting to the value, which is incredibly simple, but I reckon I can't find any formula for calculating a Fibonacci number based on it's position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a way to do this? If so, how are we able to apply these formulas to arrays?&lt;/p&gt;&#xA;\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PostsLabeled.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can jump into model building part, dividing dataset into `positive` and `negative`, here we define ****label = 0.0**** as negative and ****label = 1.0**** as positive. Split the data in to test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "positive = PostsLabeled.filter(PostsLabeled.Label > 0.0)\n",
    "negative = PostsLabeled.filter(PostsLabeled.Label < 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveTrain = positive.sample(False, 0.1,seed = 123)\n",
    "negativeTrain = negative.sample(False, 0.1,seed = 123)\n",
    "training = positiveTrain.unionAll(negativeTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------------+\n",
      "|  Id|Label|                Text|\n",
      "+----+-----+--------------------+\n",
      "| 571|  1.0|What is the optim...|\n",
      "| 936|  1.0|Looking for funct...|\n",
      "|1215|  1.0|Solution to $1-f(...|\n",
      "|1730|  1.0|How do you define...|\n",
      "|2048|  1.0|Solution(s) to 'p...|\n",
      "|2872|  1.0|How do you take t...|\n",
      "|2899|  1.0|Can this standard...|\n",
      "|3319|  1.0|Why is the number...|\n",
      "|3483|  1.0|What are some goo...|\n",
      "|4317|  1.0|Generalizing $\\su...|\n",
      "+----+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the column name \"Label\" into \"Flag\" in order to do filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "negTrainTmp1 = negativeTrain.withColumnRenamed(\"Label\", \"Flag\")\n",
    "negativeTrainTmp = negTrainTmp1.select(negTrainTmp1.Id, negTrainTmp1.Flag)\n",
    "negativeTest = negative.join( negativeTrainTmp, negative.Id == negativeTrainTmp.Id, \"LeftOuter\").\\\n",
    "                        filter(\"Flag is null\").\\\n",
    "                        select(negative.Id, negative.Text, negative.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "posTrainTmp1 = positiveTrain.withColumnRenamed(\"Label\", \"Flag\")\n",
    "positiveTrainTmp = posTrainTmp1.select(posTrainTmp1.Id, posTrainTmp1.Flag)\n",
    "\n",
    "positiveTest = positive.join( positiveTrainTmp, positive.Id == positiveTrainTmp.Id, \"LeftOuter\").\\\n",
    "                        filter(\"Flag is null\").\\\n",
    "                        select(positive.Id, positive.Text, positive.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we combine all testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = negativeTest.unionAll(positiveTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next step, We split each sentence in `Text` into words using ****Tokenizer****. For each sentence (bag of words), we use ****HashingTF**** to hash the sentence into a feature vector. After this, we then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = 20000\n",
    "numEpochs = 120\n",
    "regParam = 0.001\n",
    "\n",
    "tokenizer = Tokenizer().setInputCol(\"Text\").setOutputCol(\"Words\")\n",
    "hashingTF = HashingTF().setNumFeatures(numFeatures).\\\n",
    "                setInputCol(tokenizer.getOutputCol()).setOutputCol(\"Features\")\n",
    "lr = LogisticRegression().setMaxIter(numEpochs).setRegParam(regParam).\\\n",
    "                                    setFeaturesCol(\"Features\").setLabelCol(\"Label\").\\\n",
    "                                    setRawPredictionCol(\"Score\").setPredictionCol(\"Prediction\")\n",
    "pipeline = Pipeline().setStages([tokenizer, hashingTF, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose AUC(area under ROC as model evaluation index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC: 0.6263879068653173\n"
     ]
    }
   ],
   "source": [
    "testingResult = model.transform(testing)\n",
    "testingResultScores = testingResult.select(\"Prediction\", \"Label\").rdd.map( lambda r: (float(r[0]), float(r[1])))\n",
    "bc = BinaryClassificationMetrics(testingResultScores)\n",
    "roc = bc.areaUnderROC\n",
    "print(\"Area under the ROC:\",  roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the prediction result manually by 2 examples below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first post is ***related*** with calculus, whose label should be 1.0. It can be seen that the prediction is 1.0 as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1.0\n"
     ]
    }
   ],
   "source": [
    "testTitle = \"How can you prove that a function has no closed form integral?\"\n",
    "testBody = \"\"\"&lt;p&gt;I\\'ve come across statements in the past along the lines of &quot;function &lt;span class=&quot;math-container&quot;&gt;$f(x)$&lt;/span&gt; has no closed form integral&quot;, which I assume means that there is no combination of the operations:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;addition/subtraction&lt;/li&gt;&#xA;&lt;li&gt;multiplication/division&lt;/li&gt;&#xA;&lt;li&gt;raising to powers and roots&lt;/li&gt;&#xA;&lt;li&gt;trigonometric functions&lt;/li&gt;&#xA;&lt;li&gt;exponential functions&lt;/li&gt;&#xA;&lt;li&gt;logarithmic functions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;, which when differentiated gives the function &lt;span class=&quot;math-container&quot;&gt;$f(x)$&lt;/span&gt;. I\\'ve heard this said about the function &lt;span class=&quot;math-container&quot;&gt;$f(x) = x^x$&lt;/span&gt;, for example.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What sort of techniques are used to prove statements like this? What is this branch of mathematics called?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Merged with &quot;&lt;a href=&quot;https://math.stackexchange.com/questions/2328/&amp;quot;&amp;gt;How to prove that some functions don\\'t have a primitive&lt;/a&gt;&quot; by &lt;a href=&quot;https://math.stackexchange.com/users/918/ismael&amp;quot;&amp;gt;Ismael&amp;lt;/a&amp;gt;:  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sometimes we are told that some functions like &lt;span class=&quot;math-container&quot;&gt;$\\\\dfrac{\\\\sin(x)}{x}$&lt;/span&gt; don\\'t have an indefinite integral, or that it can\\'t be expressed in term of other simple functions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wonder how we can prove that kind of assertion?&lt;/p&gt;&#xA;\"\"\"\n",
    "testText = testTitle + testBody\n",
    "testDF = sqlContext.createDataFrame([(\"155\", testText, 1.0)], [\"Id\", \"Text\", \"Label\"])\n",
    "result = model.transform(testDF)\n",
    "prediction = result.collect()[0][7]\n",
    "print(\"Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second post is ***not related*** with calculus, whose label should be 0.0. It can be seen that the prediction is 0.0 as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  0.0\n"
     ]
    }
   ],
   "source": [
    "testTitle = \"What Does it Really Mean to Have Different Kinds of Infinities?\"\n",
    "testBody = \"\"\"&lt;p&gt;Can someone explain to me how there can be different kinds of infinities?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was reading &quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/The_Man_Who_Loved_Only_Numbers&amp;quot; rel=&quot;noreferrer&quot;&gt;The man who loved only numbers&lt;/a&gt;&quot; by &lt;a href=&quot;http://en.wikipedia.org/wiki/Paul_Hoffman_(science_writer)&amp;quot; rel=&quot;noreferrer&quot;&gt;Paul Hoffman&lt;/a&gt; and came across the concept of countable and uncountable infinities, but they\\'re only words to me.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help would be appreciated.&lt;/p&gt;&#xA;\"\"\"\n",
    "testText = testTitle + testBody\n",
    "testDF = sqlContext.createDataFrame([(\"1\", testText, 0.0)], [\"Id\", \"Text\", \"Label\"])\n",
    "result = model.transform(testDF)\n",
    "prediction = result.collect()[0][7]\n",
    "print(\"Prediction: \", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
